{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f05116d3-4a5c-431b-94a5-078a7a0de18d",
   "metadata": {},
   "source": [
    "# Appendix: DATA70302 Assignment 2\n",
    "\n",
    "## Topological Data Analysis\n",
    "\n",
    "In this assignment, we will conduct a Topological Data Analysis (TDA) of Google Trends data, using *pytrends* and *gudhi* libraries in Python. By selecting 5 keywords related to political issues and elections in the United Kingdom, weekly time series data from the last 5 years will be collected. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aba4fd3a-6017-40e2-99bc-e28a241768c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import pandas as pd\n",
    "from functools import reduce\n",
    "import math\n",
    "import numpy as np\n",
    "from pytrends.request import TrendReq\n",
    "import gudhi as gd\n",
    "import gudhi.wasserstein\n",
    "import gudhi.hera\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from scipy.stats import skew, kurtosis\n",
    "from scipy.stats import spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6feb858f-fe0c-4647-8fe1-9f84f5331391",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_finite_tuple(tpl):\n",
    "    return all(math.isfinite(item) for item in tpl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f4fa5f1-ca21-45c1-97ef-41837245b4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data\n",
    "# pytrends = TrendReq(hl='en-GB', tz=0, retries=10)\n",
    "# timeframe = 'today 5-y'   # Time frame \n",
    "\n",
    "### Fuel prices\n",
    "# keyword = ['fuel prices'] # Search term\n",
    "\n",
    "# pytrends.build_payload(kw_list=keyword,\n",
    "#                       cat=0, # Category \n",
    "#                       timeframe=timeframe,\n",
    "#                       geo='GB-ENG', # Geographic location\n",
    "#                       gprop='') # Google Search Property\n",
    "\n",
    "# interest_over_time_df = pytrends.interest_over_time() # Store the interest rate\n",
    "\n",
    "# fuelp = interest_over_time_df.reset_index() \n",
    "# fuelp.drop('isPartial', axis=1, inplace= True)\n",
    "\n",
    "\n",
    "### Petrol prices\n",
    "# keyword = ['petrol prices'] # Search term\n",
    "\n",
    "# pytrends.build_payload(kw_list=keyword,\n",
    "#                       cat=0, # Category \n",
    "#                       timeframe=timeframe,\n",
    "#                       geo='GB-ENG', # Geographic location\n",
    "#                       gprop='') # Google Search Property\n",
    "\n",
    "# interest_over_time_df = pytrends.interest_over_time() # Store the interest rate\n",
    "\n",
    "# petrolp = interest_over_time_df.reset_index() \n",
    "# petrolp.drop('isPartial', axis=1, inplace= True)\n",
    "\n",
    "\n",
    "### Diesel prices\n",
    "# keyword = ['diesel prices'] # Search term\n",
    "\n",
    "# pytrends.build_payload(kw_list=keyword,\n",
    "#                       cat=0, # Category \n",
    "#                       timeframe=timeframe,\n",
    "#                       geo='GB-ENG', # Geographic location\n",
    "#                       gprop='') # Google Search Property\n",
    "\n",
    "# interest_over_time_df = pytrends.interest_over_time() # Store the interest rate\n",
    "\n",
    "# dieselp = interest_over_time_df.reset_index() \n",
    "# dieselp.drop('isPartial', axis=1, inplace= True)\n",
    "\n",
    "\n",
    "### Job seekers\n",
    "# keyword = ['job seekers'] # Search term\n",
    "\n",
    "# pytrends.build_payload(kw_list=keyword,\n",
    "#                       cat=0, # Category \n",
    "#                       timeframe=timeframe,\n",
    "#                       geo='GB-ENG', # Geographic location\n",
    "#                       gprop='') # Google Search Property\n",
    "\n",
    "# interest_over_time_df = pytrends.interest_over_time() # Store the interest rate\n",
    "\n",
    "# jobseek = interest_over_time_df.reset_index() \n",
    "# jobseek.drop('isPartial', axis=1, inplace= True)\n",
    "\n",
    "### Job seekers allowance\n",
    "# keyword = ['job seekers allowance'] # Search term\n",
    "\n",
    "# pytrends.build_payload(kw_list=keyword,\n",
    "#                        cat=0, # Category \n",
    "#                       timeframe=timeframe,\n",
    "#                       geo='GB-ENG', # Geographic location\n",
    "#                       gprop='') # Google Search Property\n",
    "\n",
    "# interest_over_time_df = pytrends.interest_over_time() # Store the interest rate\n",
    "\n",
    "# jobal = interest_over_time_df.reset_index() \n",
    "# jobal.drop('isPartial', axis=1, inplace= True)\n",
    "\n",
    "\n",
    "### Pensions\n",
    "# keyword = ['pensions'] # Search term\n",
    "\n",
    "# pytrends.build_payload(kw_list=keyword,\n",
    "#                       cat=0, # Category \n",
    "#                       timeframe=timeframe,\n",
    "#                       geo='GB-ENG', # Geographic location\n",
    "#                       gprop='') # Google Search Property\n",
    "\n",
    "# interest_over_time_df = pytrends.interest_over_time() # Store the interest rate\n",
    "\n",
    "# pensions = interest_over_time_df.reset_index() \n",
    "# pensions.drop('isPartial', axis=1, inplace= True)\n",
    "\n",
    "\n",
    "### Export data:\n",
    "# fuelp.to_csv(\"fuelp.csv\",index=False)\n",
    "# petrolp.to_csv(\"petrolp.csv\",index=False)\n",
    "# dieselp.to_csv(\"dieselp.csv\",index=False)\n",
    "# jobseek.to_csv(\"jobseekers.csv\",index=False)\n",
    "# jobal.to_csv(\"jobal.csv\",index=False)\n",
    "# pensions.to_csv(\"pensions.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19565639-9116-4da5-8f64-0f98bafe3f21",
   "metadata": {},
   "source": [
    "## 1. Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "065bd4fa-71d7-4c85-a8a1-b39be64d52ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        date  fuel prices  petrol prices  diesel prices  job seekers  \\\n",
      "0 2020-04-12            8              8              9           99   \n",
      "1 2020-04-19           19             25             19          100   \n",
      "2 2020-04-26            9              7              9           82   \n",
      "3 2020-05-03            7              5              5           74   \n",
      "4 2020-05-10           15             16             14           79   \n",
      "\n",
      "   job seekers allowance  pensions  \n",
      "0                     95        38  \n",
      "1                     97        39  \n",
      "2                     84        45  \n",
      "3                     70        35  \n",
      "4                     74        43  \n"
     ]
    }
   ],
   "source": [
    "# Load datasets\n",
    "fuelp = pd.read_csv(\"/Users/alexander/Documents/MSc Data Science/S2/Topological Data Analysis/A2/data/fuelp.csv\")\n",
    "petrolp = pd.read_csv(\"/Users/alexander/Documents/MSc Data Science/S2/Topological Data Analysis/A2/data/petrolp.csv\")\n",
    "dieselp = pd.read_csv(\"/Users/alexander/Documents/MSc Data Science/S2/Topological Data Analysis/A2/data/dieselp.csv\")\n",
    "jobseek = pd.read_csv(\"/Users/alexander/Documents/MSc Data Science/S2/Topological Data Analysis/A2/data/jobseekers.csv\")\n",
    "allowance = pd.read_csv(\"/Users/alexander/Documents/MSc Data Science/S2/Topological Data Analysis/A2/data/jobal.csv\")\n",
    "pension = pd.read_csv(\"/Users/alexander/Documents/MSc Data Science/S2/Topological Data Analysis/A2/data/pensions.csv\")\n",
    "\n",
    "# List of all DataFrames to merge\n",
    "dfs = [fuelp, petrolp, dieselp, jobseek, allowance, pension]\n",
    "\n",
    "# Date\n",
    "for i in range(len(dfs)):\n",
    "    dfs[i]['date'] = pd.to_datetime(dfs[i]['date'], format=\"%d/%m/%y\").dt.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# Merge all on \"date\"\n",
    "merged_df = reduce(lambda left, right: pd.merge(left, right, on=\"date\", how=\"outer\"), dfs)\n",
    "\n",
    "# Date format\n",
    "merged_df[\"date\"] = pd.to_datetime(merged_df[\"date\"])\n",
    "\n",
    "# Preview result\n",
    "print(merged_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92624348-8b8c-4f24-996d-61dcd35862a0",
   "metadata": {},
   "source": [
    "## 2. Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c1ff907-eef9-4cca-918e-08382a8059c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Size:\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Set consistent colours manually\n",
    "colors = {\n",
    "    \"Prices\": \"#1f77b4\",\n",
    "    \"Economy\": \"#ff7f0e\",\n",
    "    \"Pensions\": \"#2ca02c\"\n",
    "}\n",
    "\n",
    "# Plot each trend line with matching color and different line styles\n",
    "sb.lineplot(x=\"date\", y=\"fuel prices\", data=merged_df, label=\"Fuel Prices\", color=colors[\"Prices\"], linestyle=\"-\")\n",
    "sb.lineplot(x=\"date\", y=\"petrol prices\", data=merged_df, label=\"Petrol Prices\", color=colors[\"Prices\"], linestyle=\"--\")\n",
    "sb.lineplot(x=\"date\", y=\"diesel prices\", data=merged_df, label=\"Diesel Prices\", color=colors[\"Prices\"], linestyle=\":\")\n",
    "sb.lineplot(x=\"date\", y=\"job seekers\", data=merged_df, label=\"Job Seekers\", color=colors[\"Economy\"], linestyle=\"-\")\n",
    "sb.lineplot(x=\"date\", y=\"job seekers allowance\", data=merged_df, label=\"Job Seekers Allowance\", color=colors[\"Economy\"], linestyle=\"--\")\n",
    "sb.lineplot(x=\"date\", y=\"pensions\", data=merged_df, label=\"Pensions\", color=colors[\"Pensions\"], linestyle=\"-\")\n",
    "\n",
    "# Labels and formatting\n",
    "plt.ylabel(\"Google Search Interest\")\n",
    "plt.xlabel(\"Date\")\n",
    "\n",
    "# Format x-axis: every 4 months\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%b %Y'))\n",
    "plt.gca().xaxis.set_major_locator(mdates.MonthLocator(interval=4))\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.legend(title=\"Search Term\")\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the figure to file\n",
    "plt.savefig(\"search_trends.png\", dpi=300)\n",
    "\n",
    "# Close the figure so it's not displayed or stored in notebook memory\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e377427a-ac0f-4a8f-8534-9a16a488bb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove 'date' column for statistics\n",
    "df_numeric = merged_df.drop(columns=[\"date\"])\n",
    "\n",
    "# Calculate descriptive statistics\n",
    "desc_stats = df_numeric.describe(percentiles=[.25, .5, .75]).T\n",
    "\n",
    "# Add skewness and kurtosis\n",
    "desc_stats[\"skew\"] = df_numeric.skew()\n",
    "desc_stats[\"kurtosis\"] = df_numeric.kurtosis()\n",
    "\n",
    "# Rename columns\n",
    "desc_stats = desc_stats.rename(columns={\n",
    "    \"mean\": \"Mean\",\n",
    "    \"std\": \"SD\",\n",
    "    \"min\": \"Min\",\n",
    "    \"25%\": \"Q25\",\n",
    "    \"50%\": \"Q50\",\n",
    "    \"75%\": \"Q75\",\n",
    "    \"max\": \"Max\",\n",
    "    \"skew\": \"Skew\",\n",
    "    \"kurtosis\": \"Kurt\"\n",
    "})\n",
    "\n",
    "desc_stats.style.set_caption(\"Descriptive Statistics\")\n",
    "\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0891760-d5eb-460f-89e8-8c1c5ce1fd94",
   "metadata": {},
   "source": [
    "## 3. Lagged Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd7c3128-bb79-4e72-af6e-67f905cc8bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and prepare fuel prices series\n",
    "fuel_series = merged_df[['date', 'fuel prices']].copy().dropna().reset_index(drop=True)\n",
    "\n",
    "# Create lagged features\n",
    "for lag in range(1, 5):\n",
    "    fuel_series[f'lag{lag}'] = fuel_series['fuel prices'].shift(lag)\n",
    "\n",
    "# Drop rows with NaNs introduced by lagging\n",
    "fuelP_lags = fuel_series.dropna().reset_index(drop=True)\n",
    "\n",
    "# Lags\n",
    "lags = [f\"lag{l}\" for l in range(1, 5)]\n",
    "\n",
    "# Fig\n",
    "fig, axes = plt.subplots(1, 4, figsize=(12, 5), sharey=True)\n",
    "\n",
    "for i, lag in enumerate(lags):\n",
    "    sb.scatterplot(\n",
    "        x=lag,\n",
    "        y=\"fuel prices\",\n",
    "        data=fuelP_lags,\n",
    "        ax=axes[i],\n",
    "        s=20\n",
    "    )\n",
    "    axes[i].set_xlabel(f\"{lag.capitalize()}\")\n",
    "    axes[i].set_ylabel(\"Fuel Prices\" if i == 0 else \"\")  # label only first plot for clarity\n",
    "    axes[i].set_title(\"\")  # no title\n",
    "\n",
    "    # Compute and display correlation\n",
    "    corr = np.corrcoef(fuelP_lags[lag], fuelP_lags[\"fuel prices\"])[0, 1]\n",
    "    axes[i].annotate(f\"r = {corr:.2f}\", xy=(0.5, -0.2), xycoords=\"axes fraction\",\n",
    "                     ha='center', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"/Users/alexander/Documents/GitHub/TDA-and-GoogleTrends/figs/fuel.png\", dpi=300) \n",
    "\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36b56dab-72ae-4bf5-b5cb-8ccd74e1629e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and prepare petrol prices series\n",
    "petrol_series = merged_df[['date', 'petrol prices']].copy().dropna().reset_index(drop=True)\n",
    "\n",
    "# Create lagged features\n",
    "for lag in range(1, 5):\n",
    "    petrol_series[f'lag{lag}'] = petrol_series['petrol prices'].shift(lag)\n",
    "\n",
    "# Drop rows with NaNs introduced by lagging\n",
    "petrolP_lags = petrol_series.dropna().reset_index(drop=True)\n",
    "\n",
    "# Fig\n",
    "fig, axes = plt.subplots(1, 4, figsize=(12, 5), sharey=True)\n",
    "\n",
    "for i, lag in enumerate(lags):\n",
    "    sb.scatterplot(\n",
    "        x=lag,\n",
    "        y=\"petrol prices\",\n",
    "        data=petrolP_lags,\n",
    "        ax=axes[i],\n",
    "        s=20\n",
    "    )\n",
    "    axes[i].set_xlabel(f\"{lag.capitalize()}\")\n",
    "    axes[i].set_ylabel(\"Petrol Prices\" if i == 0 else \"\")\n",
    "    axes[i].set_title(\"\")\n",
    "\n",
    "    # Compute and display correlation\n",
    "    corr = np.corrcoef(petrolP_lags[lag], petrolP_lags[\"petrol prices\"])[0, 1]\n",
    "    axes[i].annotate(f\"r = {corr:.2f}\", xy=(0.5, -0.2), xycoords=\"axes fraction\",\n",
    "                     ha='center', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"/Users/alexander/Documents/GitHub/TDA-and-GoogleTrends/figs/petrol.png\", dpi=300) \n",
    "\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "615ee0a3-2580-4838-a431-959f48aca204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and prepare diesel prices series\n",
    "diesel_series = merged_df[['date', 'diesel prices']].copy().dropna().reset_index(drop=True)\n",
    "\n",
    "# Create lagged features\n",
    "for lag in range(1, 5):\n",
    "    diesel_series[f'lag{lag}'] = diesel_series['diesel prices'].shift(lag)\n",
    "\n",
    "# Drop rows with NaNs introduced by lagging\n",
    "dieselP_lags = diesel_series.dropna().reset_index(drop=True)\n",
    "\n",
    "# Define lag columns\n",
    "lags = [f'lag{l}' for l in range(1, 5)]\n",
    "\n",
    "# Create the plot\n",
    "fig, axes = plt.subplots(1, 4, figsize=(12, 5), sharey=True)\n",
    "\n",
    "for i, lag in enumerate(lags):\n",
    "    sb.scatterplot(\n",
    "        x=lag,\n",
    "        y=\"diesel prices\",\n",
    "        data=dieselP_lags,\n",
    "        ax=axes[i],\n",
    "        s=20\n",
    "    )\n",
    "    axes[i].set_xlabel(f\"{lag.capitalize()}\")\n",
    "    axes[i].set_ylabel(\"Diesel Prices\" if i == 0 else \"\")\n",
    "    axes[i].set_title(\"\")\n",
    "\n",
    "    # Compute and display correlation\n",
    "    corr = np.corrcoef(dieselP_lags[lag], dieselP_lags[\"diesel prices\"])[0, 1]\n",
    "    axes[i].annotate(f\"r = {corr:.2f}\", xy=(0.5, -0.2), xycoords=\"axes fraction\",\n",
    "                     ha='center', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"/Users/alexander/Documents/GitHub/TDA-and-GoogleTrends/figs/diesel.png\", dpi=300) \n",
    "\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "078ae5ab-46aa-4a83-a589-a16b13eed613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and prepare job seekers series\n",
    "jobseek_series = merged_df[['date', 'job seekers']].copy().dropna().reset_index(drop=True)\n",
    "\n",
    "# Create lagged features\n",
    "for lag in range(1, 5):\n",
    "    jobseek_series[f'lag{lag}'] = jobseek_series['job seekers'].shift(lag)\n",
    "\n",
    "# Drop rows with NaNs introduced by lagging\n",
    "jobseek_lags = jobseek_series.dropna().reset_index(drop=True)\n",
    "\n",
    "# Define lag columns\n",
    "lags = [f'lag{l}' for l in range(1, 5)]\n",
    "\n",
    "# Create the plot\n",
    "fig, axes = plt.subplots(1, 4, figsize=(12, 5), sharey=True)\n",
    "\n",
    "for i, lag in enumerate(lags):\n",
    "    sb.scatterplot(\n",
    "        x=lag,\n",
    "        y=\"job seekers\",\n",
    "        data=jobseek_lags,\n",
    "        ax=axes[i],\n",
    "        s=20\n",
    "    )\n",
    "    axes[i].set_xlabel(f\"{lag.capitalize()}\")\n",
    "    axes[i].set_ylabel(\"Job Seekers\" if i == 0 else \"\")\n",
    "    axes[i].set_title(\"\")\n",
    "\n",
    "    # Compute and display correlation\n",
    "    corr = np.corrcoef(jobseek_lags[lag], jobseek_lags[\"job seekers\"])[0, 1]\n",
    "    axes[i].annotate(f\"r = {corr:.2f}\", xy=(0.5, -0.2), xycoords=\"axes fraction\",\n",
    "                     ha='center', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"/Users/alexander/Documents/GitHub/TDA-and-GoogleTrends/figs/job.png\", dpi=300) \n",
    "\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c15d1a66-6048-4cf3-af3f-aaa080cec0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and prepare job seekers allowance series\n",
    "allowance_series = merged_df[['date', 'job seekers allowance']].copy().dropna().reset_index(drop=True)\n",
    "\n",
    "# Create lagged features\n",
    "for lag in range(1, 5):\n",
    "    allowance_series[f'lag{lag}'] = allowance_series['job seekers allowance'].shift(lag)\n",
    "\n",
    "# Drop rows with NaNs\n",
    "allowance_lags = allowance_series.dropna().reset_index(drop=True)\n",
    "\n",
    "# Define lag columns\n",
    "lags = [f'lag{l}' for l in range(1, 5)]\n",
    "\n",
    "# Create plot\n",
    "fig, axes = plt.subplots(1, 4, figsize=(12, 5), sharey=True)\n",
    "\n",
    "for i, lag in enumerate(lags):\n",
    "    sb.scatterplot(\n",
    "        x=lag,\n",
    "        y=\"job seekers allowance\",\n",
    "        data=allowance_lags,\n",
    "        ax=axes[i],\n",
    "        s=20\n",
    "    )\n",
    "    axes[i].set_xlabel(f\"{lag.capitalize()}\")\n",
    "    axes[i].set_ylabel(\"Job Seekers Allowance\" if i == 0 else \"\")\n",
    "    axes[i].set_title(\"\")\n",
    "\n",
    "    # Correlation\n",
    "    corr = np.corrcoef(allowance_lags[lag], allowance_lags[\"job seekers allowance\"])[0, 1]\n",
    "    axes[i].annotate(f\"r = {corr:.2f}\", xy=(0.5, -0.2), xycoords=\"axes fraction\",\n",
    "                     ha='center', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"/Users/alexander/Documents/GitHub/TDA-and-GoogleTrends/figs/allowance.png\", dpi=300) \n",
    "\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09943216-fe9d-4bd9-ad05-f673c6498bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and prepare pensions series\n",
    "pension_series = merged_df[['date', 'pensions']].copy().dropna().reset_index(drop=True)\n",
    "\n",
    "# Create lagged features\n",
    "for lag in range(1, 5):\n",
    "    pension_series[f'lag{lag}'] = pension_series['pensions'].shift(lag)\n",
    "\n",
    "# Drop rows with NaNs\n",
    "pension_lags = pension_series.dropna().reset_index(drop=True)\n",
    "\n",
    "# Define lag columns\n",
    "lags = [f'lag{l}' for l in range(1, 5)]\n",
    "\n",
    "# Create plot\n",
    "fig, axes = plt.subplots(1, 4, figsize=(12, 5), sharey=True)\n",
    "\n",
    "for i, lag in enumerate(lags):\n",
    "    sb.scatterplot(\n",
    "        x=lag,\n",
    "        y=\"pensions\",\n",
    "        data=pension_lags,\n",
    "        ax=axes[i],\n",
    "        s=20\n",
    "    )\n",
    "    axes[i].set_xlabel(f\"{lag.capitalize()}\")\n",
    "    axes[i].set_ylabel(\"Pensions\" if i == 0 else \"\")\n",
    "    axes[i].set_title(\"\")\n",
    "\n",
    "    # Correlation\n",
    "    corr = np.corrcoef(pension_lags[lag], pension_lags[\"pensions\"])[0, 1]\n",
    "    axes[i].annotate(f\"r = {corr:.2f}\", xy=(0.5, -0.2), xycoords=\"axes fraction\",\n",
    "                     ha='center', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"/Users/alexander/Documents/GitHub/TDA-and-GoogleTrends/figs/pensions.png\", dpi=300) \n",
    "\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b19e06-98e4-4205-a21f-0007e8b52afa",
   "metadata": {},
   "source": [
    "## 4. Word clouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "83b2fe23-104f-445b-b7be-df6623a26a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select keyword columns and drop NaNs\n",
    "keyword_cols = [\n",
    "    \"fuel prices\",\n",
    "    \"petrol prices\",\n",
    "    \"diesel prices\",\n",
    "    \"job seekers\",\n",
    "    \"job seekers allowance\",\n",
    "    \"pensions\"\n",
    "]\n",
    "\n",
    "keywords_df = merged_df[keyword_cols].dropna()\n",
    "\n",
    "# Create a PairGrid\n",
    "g = sb.PairGrid(keywords_df, diag_sharey=False)\n",
    "\n",
    "# Lower triangle: scatterplots\n",
    "g.map_lower(sb.scatterplot, s=15)\n",
    "\n",
    "# Upper triangle: KDE distributions\n",
    "g.map_upper(sb.kdeplot, fill=True)\n",
    "\n",
    "# Diagonal: KDE plots\n",
    "g.map_diag(sb.kdeplot, fill=True)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"/Users/alexander/Documents/GitHub/TDA-and-GoogleTrends/figs/pc.png\", dpi=300) \n",
    "\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "232d7a8f-d1d3-4fc0-ab93-b0db31fe74e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the six relevant columns\n",
    "search_terms = [\n",
    "    \"fuel prices\", \"petrol prices\", \"diesel prices\",\n",
    "    \"job seekers\", \"job seekers allowance\", \"pensions\"\n",
    "]\n",
    "\n",
    "# Compute Pearson and Spearman correlation matrices\n",
    "pearson_corr = merged_df[search_terms].corr(method=\"pearson\")\n",
    "spearman_corr = merged_df[search_terms].corr(method=\"spearman\")\n",
    "\n",
    "# Create a combined matrix with Pearson below and Spearman above the diagonal\n",
    "combined_corr = pearson_corr.copy()\n",
    "\n",
    "for i in range(len(search_terms)):\n",
    "    for j in range(len(search_terms)):\n",
    "        if i < j:\n",
    "            combined_corr.iloc[i, j] = spearman_corr.iloc[i, j]\n",
    "        elif i > j:\n",
    "            combined_corr.iloc[i, j] = pearson_corr.iloc[i, j]\n",
    "        else:\n",
    "            combined_corr.iloc[i, j] = 1.0  # Diagonal remains 1.0\n",
    "\n",
    "# Round for display\n",
    "combined_corr = combined_corr.round(3)\n",
    "\n",
    "# combined_corr.to_csv(\"cm.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80794a7-82f3-43cc-bfb4-2de3f7140a0d",
   "metadata": {},
   "source": [
    "## 4. Persistence Homology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3765221e-5a4e-49c7-b4a8-210207279833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search terms\n",
    "pts = merged_df[[\"fuel prices\",\n",
    "    \"petrol prices\",\n",
    "    \"diesel prices\",\n",
    "    \"job seekers\",\n",
    "    \"job seekers allowance\",\n",
    "    \"pensions\"]].to_numpy()\n",
    "\n",
    "# Parameters\n",
    "maximal_radius = 50\n",
    "max_dim = 2\n",
    "\n",
    "# Construct Vietoris-Rips complex\n",
    "rips_cmplx = gd.RipsComplex( points= pts,max_edge_length = maximal_radius ) \n",
    "\n",
    "# Extract persistence\n",
    "simplex_tree = rips_cmplx.create_simplex_tree( max_dimension = max_dim )\n",
    "pers = simplex_tree.persistence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c7174655-08e5-4dbe-bcc4-fb94360839d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Birth</th>\n",
       "      <th>Death</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.316625</td>\n",
       "      <td>3.464102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.162278</td>\n",
       "      <td>3.605551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.316625</td>\n",
       "      <td>3.741657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.464102</td>\n",
       "      <td>3.741657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.162278</td>\n",
       "      <td>3.741657</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Birth     Death\n",
       "0  3.316625  3.464102\n",
       "1  3.162278  3.605551\n",
       "2  3.316625  3.741657\n",
       "3  3.464102  3.741657\n",
       "4  3.162278  3.741657"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dimensions 1:\n",
    "pers1 = pd.DataFrame(simplex_tree.persistence_intervals_in_dimension(1))\n",
    "pers1.columns = ['Birth','Death']\n",
    "pers1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "790c63e7-484c-4178-81d0-48686ad9ef92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Birth</th>\n",
       "      <th>Death</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>0.0</td>\n",
       "      <td>21.447611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>0.0</td>\n",
       "      <td>21.517435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>0.0</td>\n",
       "      <td>22.715633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Birth      Death\n",
       "256    0.0  21.447611\n",
       "257    0.0  21.517435\n",
       "258    0.0  22.715633\n",
       "259    0.0        inf\n",
       "260    0.0        inf"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dimension 0\n",
    "pers0 = pd.DataFrame(simplex_tree.persistence_intervals_in_dimension(0))\n",
    "pers0.columns = ['Birth','Death']\n",
    "pers0.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ce8043b-dbf9-4870-93db-0249ef16e6df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexander/Documents/myenv/lib/python3.13/site-packages/gudhi/persistence_graphical_tools.py:134: UserWarning: usetex mode requires dvipng.\n",
      "  warnings.warn(\"usetex mode requires dvipng.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1300x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot persistence diagram and export with Garamond font\n",
    "plt.figure(figsize=(13, 8))\n",
    "\n",
    "gd.plot_persistence_diagram(pers)\n",
    "plt.xlabel(\"Birth\", fontname=\"serif\", fontsize=10)\n",
    "plt.ylabel(\"Death\", fontname=\"serif\", fontsize=10)\n",
    "plt.title(\"Persistence Diagram\", fontname=\"serif\", fontsize=10)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"/Users/alexander/Documents/GitHub/TDA-and-GoogleTrends/figs/persistence_diagram.jpeg\", format=\"jpeg\", dpi=300)\n",
    "\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51454b3-f747-437b-b825-3ba77dff37f8",
   "metadata": {},
   "source": [
    "## 5. Time series of persistence norms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77533b5b-1fe5-4422-afc6-bdaf699203ff",
   "metadata": {},
   "source": [
    "### A: Keyword plus 1 lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8be9860c-f476-453e-be4c-770a2bb32c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract only values of importance for 'fuel prices'\n",
    "s = merged_df['fuel prices']\n",
    "\n",
    "# Creating lags0 and lag1\n",
    "embed2 = pd.concat([s, s.shift()], axis=1).dropna()\n",
    "embed2.columns = ['Lag0','Lag1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eaab65bb-9668-40a0-adf8-e71088550723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set radius and max dim:\n",
    "maximal_radius = 50\n",
    "max_dim = 2\n",
    "\n",
    "# Window lenght\n",
    "ww = 52\n",
    "\n",
    "# Shape with single lag created before\n",
    "r,c = embed2.shape\n",
    "mydata2 = embed2.iloc[:,0:c]\n",
    "\n",
    "# Define upper limit\n",
    "r2 = r-ww"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a29e0db1-4600-4755-ab60-8e92bfb7099e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blank storage arrays\n",
    "BMED = []\n",
    "BMEDd = []\n",
    "l1_norms_dim_0 = []\n",
    "l2_norms_dim_0 = []\n",
    "l1_norms_dim_1 = []\n",
    "l2_norms_dim_1 = []\n",
    "diag_dim_1 = []\n",
    "diag_dim_0 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0418e8b5-47ad-4250-827e-6352a7ef8f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the collection loop of persistence norms\n",
    "for i in range(0,r2):\n",
    " a001 = i\n",
    " a002 = i+ww-1\n",
    " mydata3 = mydata2.iloc[a001:a002,:]\n",
    " mydata4 = mydata3.to_numpy()\n",
    " rips_cmplx = gd.RipsComplex(points = mydata4,max_edge_length = maximal_radius) \n",
    " simplex_tree = rips_cmplx.create_simplex_tree( max_dimension = max_dim )\n",
    " pers = simplex_tree.persistence()\n",
    " pers = [tpl for tpl in pers if is_finite_tuple(tpl[1])]\n",
    " #Let us now compute the norms in dimension 1\n",
    " l1normDim1_local = 0\n",
    " l2normDim1_local = 0\n",
    " for ii in range(0,len(pers)):\n",
    "  if (pers[ii][0] == 1):\n",
    "   l1normDim1_local = l1normDim1_local+( pers[ii][1][1]-pers[ii][1][0] )\n",
    "   l2normDim1_local = l2normDim1_local+( pers[ii][1][1]-pers[ii][1][0] )*( pers[ii][1][1]-pers[ii][1][0] )  \n",
    "   diag_dim_1.append([a002,pers[ii][1][0],pers[ii][1][1]])\n",
    " l1_norms_dim_1.append(l1normDim1_local)\n",
    " l2_norms_dim_1.append(math.sqrt(l2normDim1_local))\n",
    " #Let us now compute the norms in dimension 0\n",
    " l1normDim0_local = 0\n",
    " l2normDim0_local = 0\n",
    " for ii in range(0,len(pers)):\n",
    "  if (pers[ii][0] == 0):\n",
    "   l1normDim0_local = l1normDim0_local+( pers[ii][1][1]-pers[ii][1][0] )\n",
    "   l2normDim0_local = l2normDim0_local+( pers[ii][1][1]-pers[ii][1][0] )*( pers[ii][1][1]-pers[ii][1][0] )\n",
    "   diag_dim_0.append([a002,pers[ii][1][0],pers[ii][1][1]])\n",
    " l1_norms_dim_0.append(l1normDim0_local)\n",
    " l2_norms_dim_0.append(math.sqrt(l2normDim0_local)) \n",
    " BMED.append([a002,l1normDim0_local,l1normDim1_local,l2normDim0_local,l2normDim1_local ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "10fc0254-0232-44e6-864e-1974be7990d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Into a dataframe\n",
    "BMEDDFL2 = pd.DataFrame(BMED)\n",
    "BMEDDFL2.columns = ['Obs','L10','L11','L20','L21']\n",
    "\n",
    "# Diagrams for use in the Wasserstein distance\n",
    "Adiag_dim_0L2 = diag_dim_0\n",
    "Adiag_dim_1L2 = diag_dim_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "85e32da0-af8e-423c-ad12-8850184c2501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with original:\n",
    "dff = merged_df.iloc[:, :2]\n",
    "\n",
    "lag=1\n",
    "dffaL2 = dff\n",
    "dffaL2['Obs'] = dffaL2.index\n",
    "dffaL2.loc[:, \"Obs\"] = dffaL2[\"Obs\"].apply(lambda x: x - lag)\n",
    "\n",
    "# Final merge\n",
    "dffbL2 = dffaL2.merge(BMEDDFL2,on='Obs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "315e377b-23b8-48e6-83df-3bbebb813477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melt the data\n",
    "df_long = dffbL2.melt(id_vars=['date'], value_vars=['L11', 'L21'], \n",
    "                      var_name='Type', value_name='Persistence Norm')\n",
    "\n",
    "# Rename for legend\n",
    "df_long['Type'] = df_long['Type'].replace({'L11': 'L1', 'L21': 'L2'})\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sb.lineplot(x='date', y='Persistence Norm', hue='Type', data=df_long)\n",
    "plt.ylabel(\"Persistence Norms\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.title(\"L1 and L2 Persistence Norms Over Time\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"/Users/alexander/Documents/GitHub/TDA-and-GoogleTrends/figs/A.jpeg\", format=\"jpeg\", dpi=300)\n",
    "\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2860af-bc9d-412c-815e-86b5bd42a118",
   "metadata": {},
   "source": [
    "### B: Keyword plus 4 lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5187f972-0257-484a-9732-a12858538720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating from lag0 to lag4\n",
    "embed5 = pd.concat([s, s.shift(), s.shift(2), s.shift(3), s.shift(4)], axis=1).dropna()\n",
    "embed5.columns = ['Lag0','Lag1', 'Lag2', 'Lag3', 'Lag4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4507cf40-60f5-4f10-a2ae-52a9bc74054b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape with single lag created before\n",
    "r,c = embed5.shape\n",
    "mydata2 = embed5.iloc[:,0:5]\n",
    "\n",
    "# Define upper limit\n",
    "r2 = r-ww"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ada972c8-b4d7-440e-adc8-ace04e9b67ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty arrays\n",
    "BMED = []\n",
    "BMEDd = []\n",
    "l1_norms_dim_0 = []\n",
    "l2_norms_dim_0 = []\n",
    "l1_norms_dim_1 = []\n",
    "l2_norms_dim_1 = []\n",
    "diag_dim_1 = []\n",
    "diag_dim_0 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3e7cb24e-5b81-4fd5-a518-2ccf72a8b389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the collection loop of persistence norms\n",
    "for i in range(0,r2):\n",
    " a001 = i\n",
    " a002 = i+ww-1\n",
    " mydata3 = mydata2.iloc[a001:a002,:]\n",
    " mydata4 = mydata3.to_numpy()\n",
    " rips_cmplx = gd.RipsComplex(points = mydata4,max_edge_length = maximal_radius) \n",
    " simplex_tree = rips_cmplx.create_simplex_tree( max_dimension = max_dim )\n",
    " pers = simplex_tree.persistence()\n",
    " pers = [tpl for tpl in pers if is_finite_tuple(tpl[1])]\n",
    " #Let us now compute the norms in dimension 1\n",
    " l1normDim1_local = 0\n",
    " l2normDim1_local = 0\n",
    " for ii in range(0,len(pers)):\n",
    "  if (pers[ii][0] == 1):\n",
    "   l1normDim1_local = l1normDim1_local+( pers[ii][1][1]-pers[ii][1][0] )\n",
    "   l2normDim1_local = l2normDim1_local+( pers[ii][1][1]-pers[ii][1][0] )*( pers[ii][1][1]-pers[ii][1][0] )  \n",
    "   diag_dim_1.append([a002,pers[ii][1][0],pers[ii][1][1]])\n",
    " l1_norms_dim_1.append(l1normDim1_local)\n",
    " l2_norms_dim_1.append(math.sqrt(l2normDim1_local))\n",
    " #Let us now compute the norms in dimension 0\n",
    " l1normDim0_local = 0\n",
    " l2normDim0_local = 0\n",
    " for ii in range(0,len(pers)):\n",
    "  if (pers[ii][0] == 0):\n",
    "   l1normDim0_local = l1normDim0_local+( pers[ii][1][1]-pers[ii][1][0] )\n",
    "   l2normDim0_local = l2normDim0_local+( pers[ii][1][1]-pers[ii][1][0] )*( pers[ii][1][1]-pers[ii][1][0] )\n",
    "   diag_dim_0.append([a002,pers[ii][1][0],pers[ii][1][1]])\n",
    " l1_norms_dim_0.append(l1normDim0_local)\n",
    " l2_norms_dim_0.append(math.sqrt(l2normDim0_local)) \n",
    " BMED.append([a002,l1normDim0_local,l1normDim1_local,l2normDim0_local,l2normDim1_local ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9c23859d-a6f5-4fd0-b3b3-fb1e9328d0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Into a dataframe\n",
    "BMEDDFL2 = pd.DataFrame(BMED)\n",
    "BMEDDFL2.columns = ['Obs','L10','L11','L20','L21']\n",
    "\n",
    "# Diagrams for use in the Wasserstein distance\n",
    "Bdiag_dim_0L2 = diag_dim_0\n",
    "Bdiag_dim_1L2 = diag_dim_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2774e162-77c5-4a2a-af8e-0daea28e0119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with original:\n",
    "dff = merged_df.iloc[:, :7]\n",
    "\n",
    "lag=1\n",
    "dffaL2 = dff\n",
    "dffaL2['Obs'] = dffaL2.index\n",
    "dffaL2.loc[:, \"Obs\"] = dffaL2[\"Obs\"].apply(lambda x: x - lag)\n",
    "\n",
    "# Final merge\n",
    "dffbL2 = dffaL2.merge(BMEDDFL2,on='Obs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b0ff2194-6238-48ed-ae16-44ce5928d46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melt the data\n",
    "df_long = dffbL2.melt(id_vars=['date'], value_vars=['L11', 'L21'], \n",
    "                      var_name='Type', value_name='Persistence Norm')\n",
    "\n",
    "# Rename for legend\n",
    "df_long['Type'] = df_long['Type'].replace({'L11': 'L1', 'L21': 'L2'})\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sb.lineplot(x='date', y='Persistence Norm', hue='Type', data=df_long)\n",
    "plt.ylabel(\"Persistence Norms\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.title(\"L1 and L2 Persistence Norms Over Time\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"/Users/alexander/Documents/GitHub/TDA-and-GoogleTrends/figs/B.jpeg\", format=\"jpeg\", dpi=300)\n",
    "\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db4ad85-cceb-4a45-9977-4f7a7973d941",
   "metadata": {},
   "source": [
    "### C: Keyword plus 1 related search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2cc949fa-30a8-42de-b96c-707f5813b6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First and second keyword\n",
    "newdf2W2 = merged_df.iloc[:, :3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5b6e1aac-49aa-40a0-9b0a-ba7307816004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters:\n",
    "maximal_radius = 50\n",
    "max_dim = 2\n",
    "\n",
    "ww = 52\n",
    "\n",
    "r,c = newdf2W2.shape\n",
    "r2 = r-ww"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1e7331f6-8ca1-4baf-86f2-c86fdac8bf85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without date\n",
    "mydata2 = newdf2W2.iloc[:,1:c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b826a413-0cfa-451f-a006-386a832dafb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty arrays\n",
    "BMED = []\n",
    "BMEDd = []\n",
    "l1_norms_dim_0 = []\n",
    "l2_norms_dim_0 = []\n",
    "l1_norms_dim_1 = []\n",
    "l2_norms_dim_1 = []\n",
    "diag_dim_1 = []\n",
    "diag_dim_0 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dc4e6692-2fef-4332-9d77-61a4c1d6be7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,r2):\n",
    " a001 = i\n",
    " a002 = i+ww-1\n",
    " mydata3 = mydata2.iloc[a001:a002,:]\n",
    " mydata4 = mydata3.to_numpy()\n",
    " rips_cmplx = gd.RipsComplex(points = mydata4,max_edge_length = maximal_radius) \n",
    " simplex_tree = rips_cmplx.create_simplex_tree( max_dimension = max_dim )\n",
    " pers = simplex_tree.persistence()\n",
    " pers = [tpl for tpl in pers if is_finite_tuple(tpl[1])]\n",
    " #Let us now compute the norms in dimension 1\n",
    " l1normDim1_local = 0\n",
    " l2normDim1_local = 0\n",
    " for ii in range(0,len(pers)):\n",
    "  if (pers[ii][0] == 1):\n",
    "   l1normDim1_local = l1normDim1_local+( pers[ii][1][1]-pers[ii][1][0] )\n",
    "   l2normDim1_local = l2normDim1_local+( pers[ii][1][1]-pers[ii][1][0] )*( pers[ii][1][1]-pers[ii][1][0] )  \n",
    "   diag_dim_1.append([a002,pers[ii][1][0],pers[ii][1][1]])\n",
    " l1_norms_dim_1.append(l1normDim1_local)\n",
    " l2_norms_dim_1.append(math.sqrt(l2normDim1_local))\n",
    " #Let us now compute the norms in dimension 0\n",
    " l1normDim0_local = 0\n",
    " l2normDim0_local = 0\n",
    " for ii in range(0,len(pers)):\n",
    "  if (pers[ii][0] == 0):\n",
    "   l1normDim0_local = l1normDim0_local+( pers[ii][1][1]-pers[ii][1][0] )\n",
    "   l2normDim0_local = l2normDim0_local+( pers[ii][1][1]-pers[ii][1][0] )*( pers[ii][1][1]-pers[ii][1][0] )\n",
    "   diag_dim_0.append([a002,pers[ii][1][0],pers[ii][1][1]])\n",
    " l1_norms_dim_0.append(l1normDim0_local)\n",
    " l2_norms_dim_0.append(math.sqrt(l2normDim0_local)) \n",
    " BMED.append([a002,l1normDim0_local,l1normDim1_local,l2normDim0_local,l2normDim1_local ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "579aa911-dce8-4ae1-9638-1245c821ea58",
   "metadata": {},
   "outputs": [],
   "source": [
    "BMEDDF2W2 = pd.DataFrame(BMED)\n",
    "BMEDDF2W2.columns = ['Obs','L10','L11','L20','L21']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "02698c2d-5ac8-47bf-b9eb-17984245a233",
   "metadata": {},
   "outputs": [],
   "source": [
    "Cdiag_dim_0W2 = diag_dim_0\n",
    "Cdiag_dim_1W2 = diag_dim_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ba8ce36b-299a-429d-becd-3f95e3c48856",
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf2aW2 = newdf2W2\n",
    "newdf2aW2['Obs'] = newdf2aW2.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2cd2aa23-6372-4dce-aca4-2bca0e3631e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf2bW2 = newdf2aW2.merge(BMEDDF2W2,on='Obs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5035ecf6-5059-4213-82ad-defecdd8479d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melt the data\n",
    "df_long = newdf2bW2.melt(id_vars=['date'], value_vars=['L11', 'L21'], \n",
    "                      var_name='Type', value_name='Persistence Norm')\n",
    "\n",
    "# Rename for legend\n",
    "df_long['Type'] = df_long['Type'].replace({'L11': 'L1', 'L21': 'L2'})\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sb.lineplot(x='date', y='Persistence Norm', hue='Type', data=df_long)\n",
    "plt.ylabel(\"Persistence Norms\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.title(\"L1 and L2 Persistence Norms Over Time\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"/Users/alexander/Documents/GitHub/TDA-and-GoogleTrends/figs/C.jpeg\", format=\"jpeg\", dpi=300)\n",
    "\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bbbeadf8-410e-4431-9122-1c117d200517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_2c51b\">\n",
       "  <caption>Summary Table</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_2c51b_level0_col0\" class=\"col_heading level0 col0\" >Mean</th>\n",
       "      <th id=\"T_2c51b_level0_col1\" class=\"col_heading level0 col1\" >SD</th>\n",
       "      <th id=\"T_2c51b_level0_col2\" class=\"col_heading level0 col2\" >Min</th>\n",
       "      <th id=\"T_2c51b_level0_col3\" class=\"col_heading level0 col3\" >Q25</th>\n",
       "      <th id=\"T_2c51b_level0_col4\" class=\"col_heading level0 col4\" >Median</th>\n",
       "      <th id=\"T_2c51b_level0_col5\" class=\"col_heading level0 col5\" >Q75</th>\n",
       "      <th id=\"T_2c51b_level0_col6\" class=\"col_heading level0 col6\" >Max</th>\n",
       "      <th id=\"T_2c51b_level0_col7\" class=\"col_heading level0 col7\" >Skew</th>\n",
       "      <th id=\"T_2c51b_level0_col8\" class=\"col_heading level0 col8\" >Kurtosis</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Metric</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "      <th class=\"blank col6\" >&nbsp;</th>\n",
       "      <th class=\"blank col7\" >&nbsp;</th>\n",
       "      <th class=\"blank col8\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_2c51b_level0_row0\" class=\"row_heading level0 row0\" >L11</th>\n",
       "      <td id=\"T_2c51b_row0_col0\" class=\"data row0 col0\" >2.410789</td>\n",
       "      <td id=\"T_2c51b_row0_col1\" class=\"data row0 col1\" >0.633980</td>\n",
       "      <td id=\"T_2c51b_row0_col2\" class=\"data row0 col2\" >1.242641</td>\n",
       "      <td id=\"T_2c51b_row0_col3\" class=\"data row0 col3\" >2.000000</td>\n",
       "      <td id=\"T_2c51b_row0_col4\" class=\"data row0 col4\" >2.414214</td>\n",
       "      <td id=\"T_2c51b_row0_col5\" class=\"data row0 col5\" >2.656854</td>\n",
       "      <td id=\"T_2c51b_row0_col6\" class=\"data row0 col6\" >4.249213</td>\n",
       "      <td id=\"T_2c51b_row0_col7\" class=\"data row0 col7\" >0.666210</td>\n",
       "      <td id=\"T_2c51b_row0_col8\" class=\"data row0 col8\" >0.114358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2c51b_level0_row1\" class=\"row_heading level0 row1\" >L21</th>\n",
       "      <td id=\"T_2c51b_row1_col0\" class=\"data row1 col0\" >1.411712</td>\n",
       "      <td id=\"T_2c51b_row1_col1\" class=\"data row1 col1\" >0.997606</td>\n",
       "      <td id=\"T_2c51b_row1_col2\" class=\"data row1 col2\" >0.454602</td>\n",
       "      <td id=\"T_2c51b_row1_col3\" class=\"data row1 col3\" >0.857864</td>\n",
       "      <td id=\"T_2c51b_row1_col4\" class=\"data row1 col4\" >1.029437</td>\n",
       "      <td id=\"T_2c51b_row1_col5\" class=\"data row1 col5\" >1.230447</td>\n",
       "      <td id=\"T_2c51b_row1_col6\" class=\"data row1 col6\" >4.261165</td>\n",
       "      <td id=\"T_2c51b_row1_col7\" class=\"data row1 col7\" >1.722548</td>\n",
       "      <td id=\"T_2c51b_row1_col8\" class=\"data row1 col8\" >1.511572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2c51b_level0_row2\" class=\"row_heading level0 row2\" >L10</th>\n",
       "      <td id=\"T_2c51b_row2_col0\" class=\"data row2 col0\" >59.988820</td>\n",
       "      <td id=\"T_2c51b_row2_col1\" class=\"data row2 col1\" >47.929889</td>\n",
       "      <td id=\"T_2c51b_row2_col2\" class=\"data row2 col2\" >13.414214</td>\n",
       "      <td id=\"T_2c51b_row2_col3\" class=\"data row2 col3\" >22.990705</td>\n",
       "      <td id=\"T_2c51b_row2_col4\" class=\"data row2 col4\" >35.505046</td>\n",
       "      <td id=\"T_2c51b_row2_col5\" class=\"data row2 col5\" >105.464934</td>\n",
       "      <td id=\"T_2c51b_row2_col6\" class=\"data row2 col6\" >147.704915</td>\n",
       "      <td id=\"T_2c51b_row2_col7\" class=\"data row2 col7\" >0.750469</td>\n",
       "      <td id=\"T_2c51b_row2_col8\" class=\"data row2 col8\" >-1.126821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2c51b_level0_row3\" class=\"row_heading level0 row3\" >L20</th>\n",
       "      <td id=\"T_2c51b_row3_col0\" class=\"data row3 col0\" >329.595238</td>\n",
       "      <td id=\"T_2c51b_row3_col1\" class=\"data row3 col1\" >395.165418</td>\n",
       "      <td id=\"T_2c51b_row3_col2\" class=\"data row3 col2\" >14.000000</td>\n",
       "      <td id=\"T_2c51b_row3_col3\" class=\"data row3 col3\" >31.250000</td>\n",
       "      <td id=\"T_2c51b_row3_col4\" class=\"data row3 col4\" >60.000000</td>\n",
       "      <td id=\"T_2c51b_row3_col5\" class=\"data row3 col5\" >853.500000</td>\n",
       "      <td id=\"T_2c51b_row3_col6\" class=\"data row3 col6\" >1600.000000</td>\n",
       "      <td id=\"T_2c51b_row3_col7\" class=\"data row3 col7\" >0.839540</td>\n",
       "      <td id=\"T_2c51b_row3_col8\" class=\"data row3 col8\" >-0.919261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2c51b_level0_row4\" class=\"row_heading level0 row4\" >Avg_STD_terms</th>\n",
       "      <td id=\"T_2c51b_row4_col0\" class=\"data row4 col0\" >7.814671</td>\n",
       "      <td id=\"T_2c51b_row4_col1\" class=\"data row4 col1\" >7.008766</td>\n",
       "      <td id=\"T_2c51b_row4_col2\" class=\"data row4 col2\" >1.071892</td>\n",
       "      <td id=\"T_2c51b_row4_col3\" class=\"data row4 col3\" >1.995032</td>\n",
       "      <td id=\"T_2c51b_row4_col4\" class=\"data row4 col4\" >2.547577</td>\n",
       "      <td id=\"T_2c51b_row4_col5\" class=\"data row4 col5\" >16.359632</td>\n",
       "      <td id=\"T_2c51b_row4_col6\" class=\"data row4 col6\" >18.556411</td>\n",
       "      <td id=\"T_2c51b_row4_col7\" class=\"data row4 col7\" >0.464994</td>\n",
       "      <td id=\"T_2c51b_row4_col8\" class=\"data row4 col8\" >-1.593036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2c51b_level0_row5\" class=\"row_heading level0 row5\" >Avg_Correlation</th>\n",
       "      <td id=\"T_2c51b_row5_col0\" class=\"data row5 col0\" >0.855378</td>\n",
       "      <td id=\"T_2c51b_row5_col1\" class=\"data row5 col1\" >0.120446</td>\n",
       "      <td id=\"T_2c51b_row5_col2\" class=\"data row5 col2\" >0.588196</td>\n",
       "      <td id=\"T_2c51b_row5_col3\" class=\"data row5 col3\" >0.774141</td>\n",
       "      <td id=\"T_2c51b_row5_col4\" class=\"data row5 col4\" >0.869024</td>\n",
       "      <td id=\"T_2c51b_row5_col5\" class=\"data row5 col5\" >0.973844</td>\n",
       "      <td id=\"T_2c51b_row5_col6\" class=\"data row5 col6\" >0.983724</td>\n",
       "      <td id=\"T_2c51b_row5_col7\" class=\"data row5 col7\" >-0.510880</td>\n",
       "      <td id=\"T_2c51b_row5_col8\" class=\"data row5 col8\" >-1.047241</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1163dee90>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter to ensure we're summarising only rows with persistence norms\n",
    "norms_df = newdf2bW2.dropna(subset=['L10', 'L11', 'L20', 'L21'])\n",
    "\n",
    "# Function to compute summary stats for a column or list\n",
    "def summarise_column(col):\n",
    "    return {\n",
    "        'Mean': np.mean(col),\n",
    "        'SD': np.std(col),\n",
    "        'Min': np.min(col),\n",
    "        'Q25': np.percentile(col, 25),\n",
    "        'Median': np.median(col),\n",
    "        'Q75': np.percentile(col, 75),\n",
    "        'Max': np.max(col),\n",
    "        'Skew': skew(col),\n",
    "        'Kurtosis': kurtosis(col)\n",
    "    }\n",
    "\n",
    "# Create summary table for each of the persistence norm columns\n",
    "summary_data = {}\n",
    "for col in ['L11', 'L21', 'L10', 'L20']:\n",
    "    summary_data[col] = summarise_column(norms_df[col])\n",
    "\n",
    "# === Now compute average STD and correlation across same 52-week windows ===\n",
    "keywords = ['fuel prices', 'petrol prices']\n",
    "X = newdf2bW2[keywords]\n",
    "window_size = 52\n",
    "avg_stds = []\n",
    "avg_corrs = []\n",
    "\n",
    "for i in range(len(X) - window_size):\n",
    "    window = X.iloc[i:i + window_size]\n",
    "    stds = window.std()\n",
    "    corr_matrix = window.corr()\n",
    "    upper_triangle = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "    avg_stds.append(stds.mean())\n",
    "    avg_corrs.append(upper_triangle.stack().mean())\n",
    "\n",
    "# Add their summaries\n",
    "summary_data['Avg_STD_terms'] = summarise_column(avg_stds)\n",
    "summary_data['Avg_Correlation'] = summarise_column(avg_corrs)\n",
    "\n",
    "# Convert to DataFrame\n",
    "summary_df = pd.DataFrame(summary_data).T\n",
    "summary_df.index.name = 'Metric'\n",
    "\n",
    "# (Optional) Display in notebook or export\n",
    "summary_df.style.set_caption(\"Summary Table\")\n",
    "# summary_df.to_csv(\"norms2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6ff5a9-0281-4144-9a50-32ea69d40575",
   "metadata": {},
   "source": [
    "### D: Keyword plus 5 related searches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c015dd2e-38a8-465f-8262-118da1e325de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All data:\n",
    "newdf2W2 = merged_df.iloc[:, :7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ee23ee58-57be-4756-bd2b-eab0d210430b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters:\n",
    "maximal_radius = 50\n",
    "max_dim = 2\n",
    "\n",
    "ww = 52\n",
    "\n",
    "r,c = newdf2W2.shape\n",
    "r2 = r-ww"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4bba2925-8319-47ac-be1a-69f99f0bc4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without date\n",
    "mydata2 = newdf2W2.iloc[:,1:c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2909ce9f-fa85-445d-ba0a-1bea32125c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty arrays\n",
    "BMED = []\n",
    "BMEDd = []\n",
    "l1_norms_dim_0 = []\n",
    "l2_norms_dim_0 = []\n",
    "l1_norms_dim_1 = []\n",
    "l2_norms_dim_1 = []\n",
    "diag_dim_1 = []\n",
    "diag_dim_0 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "77362402-b73b-47c0-8db6-61275cbb0eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,r2):\n",
    " a001 = i\n",
    " a002 = i+ww-1\n",
    " mydata3 = mydata2.iloc[a001:a002,:]\n",
    " mydata4 = mydata3.to_numpy()\n",
    " rips_cmplx = gd.RipsComplex(points = mydata4,max_edge_length = maximal_radius) \n",
    " simplex_tree = rips_cmplx.create_simplex_tree( max_dimension = max_dim )\n",
    " pers = simplex_tree.persistence()\n",
    " pers = [tpl for tpl in pers if is_finite_tuple(tpl[1])]\n",
    " #Let us now compute the norms in dimension 1\n",
    " l1normDim1_local = 0\n",
    " l2normDim1_local = 0\n",
    " for ii in range(0,len(pers)):\n",
    "  if (pers[ii][0] == 1):\n",
    "   l1normDim1_local = l1normDim1_local+( pers[ii][1][1]-pers[ii][1][0] )\n",
    "   l2normDim1_local = l2normDim1_local+( pers[ii][1][1]-pers[ii][1][0] )*( pers[ii][1][1]-pers[ii][1][0] )  \n",
    "   diag_dim_1.append([a002,pers[ii][1][0],pers[ii][1][1]])\n",
    " l1_norms_dim_1.append(l1normDim1_local)\n",
    " l2_norms_dim_1.append(math.sqrt(l2normDim1_local))\n",
    " #Let us now compute the norms in dimension 0\n",
    " l1normDim0_local = 0\n",
    " l2normDim0_local = 0\n",
    " for ii in range(0,len(pers)):\n",
    "  if (pers[ii][0] == 0):\n",
    "   l1normDim0_local = l1normDim0_local+( pers[ii][1][1]-pers[ii][1][0] )\n",
    "   l2normDim0_local = l2normDim0_local+( pers[ii][1][1]-pers[ii][1][0] )*( pers[ii][1][1]-pers[ii][1][0] )\n",
    "   diag_dim_0.append([a002,pers[ii][1][0],pers[ii][1][1]])\n",
    " l1_norms_dim_0.append(l1normDim0_local)\n",
    " l2_norms_dim_0.append(math.sqrt(l2normDim0_local)) \n",
    " BMED.append([a002,l1normDim0_local,l1normDim1_local,l2normDim0_local,l2normDim1_local ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "32f8145b-49b5-422d-89d5-0761f922a7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "BMEDDF2W2 = pd.DataFrame(BMED)\n",
    "BMEDDF2W2.columns = ['Obs','L10','L11','L20','L21']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fea9a036-4143-435e-a4bb-9dc26322dda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ddiag_dim_0W2 = diag_dim_0\n",
    "Ddiag_dim_1W2 = diag_dim_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3c6444f1-576b-494e-b7da-bdc39647de08",
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf2aW2 = newdf2W2\n",
    "newdf2aW2['Obs'] = newdf2aW2.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "78b8a156-84e3-4a68-92a7-5568ba0f29c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf2bW2 = newdf2aW2.merge(BMEDDF2W2,on='Obs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6729b841-91bf-4b2a-8724-630d14847966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melt the data\n",
    "df_long = newdf2bW2.melt(id_vars=['date'], value_vars=['L11', 'L21'], \n",
    "                      var_name='Type', value_name='Persistence Norm')\n",
    "\n",
    "# Rename for legend\n",
    "df_long['Type'] = df_long['Type'].replace({'L11': 'L1', 'L21': 'L2'})\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sb.lineplot(x='date', y='Persistence Norm', hue='Type', data=df_long)\n",
    "plt.ylabel(\"Persistence Norms\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.title(\"L1 and L2 Persistence Norms Over Time\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"/Users/alexander/Documents/GitHub/TDA-and-GoogleTrends/figs/D.jpeg\", format=\"jpeg\", dpi=300)\n",
    "\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "98a9d054-0ec1-4016-9ad0-7c1189dcc938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_be6f0\">\n",
       "  <caption>Summary Table</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_be6f0_level0_col0\" class=\"col_heading level0 col0\" >Mean</th>\n",
       "      <th id=\"T_be6f0_level0_col1\" class=\"col_heading level0 col1\" >SD</th>\n",
       "      <th id=\"T_be6f0_level0_col2\" class=\"col_heading level0 col2\" >Min</th>\n",
       "      <th id=\"T_be6f0_level0_col3\" class=\"col_heading level0 col3\" >Q25</th>\n",
       "      <th id=\"T_be6f0_level0_col4\" class=\"col_heading level0 col4\" >Median</th>\n",
       "      <th id=\"T_be6f0_level0_col5\" class=\"col_heading level0 col5\" >Q75</th>\n",
       "      <th id=\"T_be6f0_level0_col6\" class=\"col_heading level0 col6\" >Max</th>\n",
       "      <th id=\"T_be6f0_level0_col7\" class=\"col_heading level0 col7\" >Skew</th>\n",
       "      <th id=\"T_be6f0_level0_col8\" class=\"col_heading level0 col8\" >Kurtosis</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Metric</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "      <th class=\"blank col6\" >&nbsp;</th>\n",
       "      <th class=\"blank col7\" >&nbsp;</th>\n",
       "      <th class=\"blank col8\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_be6f0_level0_row0\" class=\"row_heading level0 row0\" >L11</th>\n",
       "      <td id=\"T_be6f0_row0_col0\" class=\"data row0 col0\" >5.977416</td>\n",
       "      <td id=\"T_be6f0_row0_col1\" class=\"data row0 col1\" >3.461017</td>\n",
       "      <td id=\"T_be6f0_row0_col2\" class=\"data row0 col2\" >0.930889</td>\n",
       "      <td id=\"T_be6f0_row0_col3\" class=\"data row0 col3\" >3.687316</td>\n",
       "      <td id=\"T_be6f0_row0_col4\" class=\"data row0 col4\" >5.150029</td>\n",
       "      <td id=\"T_be6f0_row0_col5\" class=\"data row0 col5\" >7.229589</td>\n",
       "      <td id=\"T_be6f0_row0_col6\" class=\"data row0 col6\" >16.790225</td>\n",
       "      <td id=\"T_be6f0_row0_col7\" class=\"data row0 col7\" >1.029524</td>\n",
       "      <td id=\"T_be6f0_row0_col8\" class=\"data row0 col8\" >0.467835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_be6f0_level0_row1\" class=\"row_heading level0 row1\" >L21</th>\n",
       "      <td id=\"T_be6f0_row1_col0\" class=\"data row1 col0\" >7.276438</td>\n",
       "      <td id=\"T_be6f0_row1_col1\" class=\"data row1 col1\" >6.797778</td>\n",
       "      <td id=\"T_be6f0_row1_col2\" class=\"data row1 col2\" >0.515092</td>\n",
       "      <td id=\"T_be6f0_row1_col3\" class=\"data row1 col3\" >2.590920</td>\n",
       "      <td id=\"T_be6f0_row1_col4\" class=\"data row1 col4\" >4.943990</td>\n",
       "      <td id=\"T_be6f0_row1_col5\" class=\"data row1 col5\" >9.152585</td>\n",
       "      <td id=\"T_be6f0_row1_col6\" class=\"data row1 col6\" >34.348299</td>\n",
       "      <td id=\"T_be6f0_row1_col7\" class=\"data row1 col7\" >1.612433</td>\n",
       "      <td id=\"T_be6f0_row1_col8\" class=\"data row1 col8\" >2.272168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_be6f0_level0_row2\" class=\"row_heading level0 row2\" >L10</th>\n",
       "      <td id=\"T_be6f0_row2_col0\" class=\"data row2 col0\" >282.939072</td>\n",
       "      <td id=\"T_be6f0_row2_col1\" class=\"data row2 col1\" >80.138487</td>\n",
       "      <td id=\"T_be6f0_row2_col2\" class=\"data row2 col2\" >178.580006</td>\n",
       "      <td id=\"T_be6f0_row2_col3\" class=\"data row2 col3\" >220.596021</td>\n",
       "      <td id=\"T_be6f0_row2_col4\" class=\"data row2 col4\" >245.990413</td>\n",
       "      <td id=\"T_be6f0_row2_col5\" class=\"data row2 col5\" >351.071883</td>\n",
       "      <td id=\"T_be6f0_row2_col6\" class=\"data row2 col6\" >447.530105</td>\n",
       "      <td id=\"T_be6f0_row2_col7\" class=\"data row2 col7\" >0.740302</td>\n",
       "      <td id=\"T_be6f0_row2_col8\" class=\"data row2 col8\" >-0.895939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_be6f0_level0_row3\" class=\"row_heading level0 row3\" >L20</th>\n",
       "      <td id=\"T_be6f0_row3_col0\" class=\"data row3 col0\" >2497.671429</td>\n",
       "      <td id=\"T_be6f0_row3_col1\" class=\"data row3 col1\" >1277.407330</td>\n",
       "      <td id=\"T_be6f0_row3_col2\" class=\"data row3 col2\" >947.000000</td>\n",
       "      <td id=\"T_be6f0_row3_col3\" class=\"data row3 col3\" >1612.250000</td>\n",
       "      <td id=\"T_be6f0_row3_col4\" class=\"data row3 col4\" >1933.000000</td>\n",
       "      <td id=\"T_be6f0_row3_col5\" class=\"data row3 col5\" >3699.000000</td>\n",
       "      <td id=\"T_be6f0_row3_col6\" class=\"data row3 col6\" >5414.000000</td>\n",
       "      <td id=\"T_be6f0_row3_col7\" class=\"data row3 col7\" >0.705189</td>\n",
       "      <td id=\"T_be6f0_row3_col8\" class=\"data row3 col8\" >-0.985368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_be6f0_level0_row4\" class=\"row_heading level0 row4\" >Avg_STD_terms</th>\n",
       "      <td id=\"T_be6f0_row4_col0\" class=\"data row4 col0\" >6.850900</td>\n",
       "      <td id=\"T_be6f0_row4_col1\" class=\"data row4 col1\" >3.339188</td>\n",
       "      <td id=\"T_be6f0_row4_col2\" class=\"data row4 col2\" >3.188640</td>\n",
       "      <td id=\"T_be6f0_row4_col3\" class=\"data row4 col3\" >3.819080</td>\n",
       "      <td id=\"T_be6f0_row4_col4\" class=\"data row4 col4\" >5.004469</td>\n",
       "      <td id=\"T_be6f0_row4_col5\" class=\"data row4 col5\" >10.938815</td>\n",
       "      <td id=\"T_be6f0_row4_col6\" class=\"data row4 col6\" >11.700111</td>\n",
       "      <td id=\"T_be6f0_row4_col7\" class=\"data row4 col7\" >0.390993</td>\n",
       "      <td id=\"T_be6f0_row4_col8\" class=\"data row4 col8\" >-1.642316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_be6f0_level0_row5\" class=\"row_heading level0 row5\" >Avg_Correlation</th>\n",
       "      <td id=\"T_be6f0_row5_col0\" class=\"data row5 col0\" >0.278083</td>\n",
       "      <td id=\"T_be6f0_row5_col1\" class=\"data row5 col1\" >0.118533</td>\n",
       "      <td id=\"T_be6f0_row5_col2\" class=\"data row5 col2\" >0.066711</td>\n",
       "      <td id=\"T_be6f0_row5_col3\" class=\"data row5 col3\" >0.181179</td>\n",
       "      <td id=\"T_be6f0_row5_col4\" class=\"data row5 col4\" >0.277060</td>\n",
       "      <td id=\"T_be6f0_row5_col5\" class=\"data row5 col5\" >0.367681</td>\n",
       "      <td id=\"T_be6f0_row5_col6\" class=\"data row5 col6\" >0.498578</td>\n",
       "      <td id=\"T_be6f0_row5_col7\" class=\"data row5 col7\" >-0.060607</td>\n",
       "      <td id=\"T_be6f0_row5_col8\" class=\"data row5 col8\" >-1.033078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x116907360>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter to ensure we're summarising only rows with persistence norms\n",
    "norms_df = newdf2bW2.dropna(subset=['L10', 'L11', 'L20', 'L21'])\n",
    "\n",
    "# Function to compute summary stats for a column or list\n",
    "def summarise_column(col):\n",
    "    return {\n",
    "        'Mean': np.mean(col),\n",
    "        'SD': np.std(col),\n",
    "        'Min': np.min(col),\n",
    "        'Q25': np.percentile(col, 25),\n",
    "        'Median': np.median(col),\n",
    "        'Q75': np.percentile(col, 75),\n",
    "        'Max': np.max(col),\n",
    "        'Skew': skew(col),\n",
    "        'Kurtosis': kurtosis(col)\n",
    "    }\n",
    "\n",
    "# Create summary table for each of the persistence norm columns\n",
    "summary_data = {}\n",
    "for col in ['L11', 'L21', 'L10', 'L20']:\n",
    "    summary_data[col] = summarise_column(norms_df[col])\n",
    "\n",
    "# === Now compute average STD and correlation across same 52-week windows ===\n",
    "keywords = ['fuel prices', 'petrol prices', 'diesel prices',\n",
    "            'job seekers', 'job seekers allowance', 'pensions']\n",
    "X = newdf2bW2[keywords]\n",
    "window_size = 52\n",
    "avg_stds = []\n",
    "avg_corrs = []\n",
    "\n",
    "for i in range(len(X) - window_size):\n",
    "    window = X.iloc[i:i + window_size]\n",
    "    stds = window.std()\n",
    "    corr_matrix = window.corr()\n",
    "    upper_triangle = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "    avg_stds.append(stds.mean())\n",
    "    avg_corrs.append(upper_triangle.stack().mean())\n",
    "\n",
    "# Add their summaries\n",
    "summary_data['Avg_STD_terms'] = summarise_column(avg_stds)\n",
    "summary_data['Avg_Correlation'] = summarise_column(avg_corrs)\n",
    "\n",
    "# Convert to DataFrame\n",
    "summary_df = pd.DataFrame(summary_data).T\n",
    "summary_df.index.name = 'Metric'\n",
    "\n",
    "# (Optional) Display in notebook or export\n",
    "summary_df.style.set_caption(\"Summary Table\")\n",
    "# summary_df.to_csv(\"norms.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1227a3d-c08d-4136-9c04-73062f66e866",
   "metadata": {},
   "source": [
    "## Wassertein Distances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fff58e-4657-4818-96a9-1a5e95670acc",
   "metadata": {},
   "source": [
    "### A: Keyword and 1 lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ebf898e1-8a7d-4def-8167-44766615f248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stored diagrams\n",
    "diagd1 = pd.DataFrame(Adiag_dim_1L2,columns=['Obs','b','d'])\n",
    "diagd0 = pd.DataFrame(Adiag_dim_0L2,columns=['Obs','b','d'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8fc2ff64-9c57-4d7c-a15f-43c77b8a8282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collecting\n",
    "diagd150 = diagd1[(diagd1['Obs'] == 52)]\n",
    "diagd150 = diagd150[['b','d']]\n",
    "diagd151 = diagd1[(diagd1['Obs'] == 53)]\n",
    "diagd151 = diagd151[['b','d']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0e5b60ef-e400-4ff1-bf5c-32e648ab604a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating distances\n",
    "diagd150a = diagd150.to_numpy()\n",
    "diagd151a = diagd151.to_numpy()\n",
    "\n",
    "dist = gd.hera.wasserstein_distance(diagd150a,diagd151a, order=1., internal_p=2.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a74df58d-e491-4d96-8122-3eaa3511cecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blank arrays\n",
    "wass0 = []\n",
    "wass1 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "caff93fa-e144-46bd-95f9-162e3c2210e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape parameters\n",
    "r,c = embed2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "736aa0d6-1684-40f6-8a85-909fd9def04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collection of Wasserstein distances\n",
    "r3 = r-1\n",
    "\n",
    "for i in range(ww,r3):\n",
    " a005 = i+1\n",
    " diagd150 = diagd1[(diagd1['Obs'] == i)]\n",
    " diagd150 = diagd150[['b','d']]\n",
    " diagd151 = diagd1[(diagd1['Obs'] == a005)]\n",
    " diagd151 = diagd151[['b','d']]\n",
    " diagd150a = diagd150.to_numpy()\n",
    " diagd151a = diagd151.to_numpy()\n",
    " dist = gudhi.hera.wasserstein_distance(diagd150a,diagd151a, order=1., internal_p=2.)\n",
    " wass1.append([a005,dist])\n",
    " diagd150 = diagd0[(diagd0['Obs'] == i)]\n",
    " diagd150 = diagd150[['b','d']]\n",
    " diagd151 = diagd0[(diagd0['Obs'] == a005)]\n",
    " diagd151 = diagd151[['b','d']]\n",
    " diagd150a = diagd150.to_numpy()\n",
    " diagd151a = diagd151.to_numpy()\n",
    " dist = gudhi.hera.wasserstein_distance(diagd150a,diagd151a, order=1., internal_p=2.)\n",
    " wass0.append([a005,dist])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "be236d72-3445-455a-8bca-88b533e35e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Into dataframes:\n",
    "wass0dfL2 = pd.DataFrame(wass0)\n",
    "wass0dfL2.columns = ['Obs','wass0']\n",
    "\n",
    "wass1dfL2 = pd.DataFrame(wass1)\n",
    "wass1dfL2.columns = ['Obs','wass1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4e276bee-4cfb-499d-87d0-ccdc57b4fa43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge:\n",
    "wass0dfbL2 = wass0dfL2.merge(dffbL2,on='Obs')\n",
    "wassdfbL2 = wass0dfbL2.merge(wass1dfL2,on='Obs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6d2417a9-cede-41ec-90d6-08276c6635bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure date is datetime\n",
    "wassdfbL2[\"date\"] = pd.to_datetime(wassdfbL2[\"date\"])\n",
    "\n",
    "# Set up the figure and primary axis\n",
    "fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Plot Dimension 0 (left y-axis)\n",
    "color0 = \"tab:blue\"\n",
    "ax1.set_xlabel(\"Date\")\n",
    "ax1.set_ylabel(\"Wasserstein Distance (Dim 0)\", color=color0)\n",
    "ax1.plot(wassdfbL2[\"date\"], wassdfbL2[\"wass0\"], color=color0, label=\"Dimension 0\")\n",
    "ax1.tick_params(axis='y', labelcolor=color0)\n",
    "\n",
    "# Add secondary y-axis for Dimension 1\n",
    "ax2 = ax1.twinx()\n",
    "color1 = \"tab:orange\"\n",
    "ax2.set_ylabel(\"Wasserstein Distance (Dim 1)\", color=color1)\n",
    "ax2.plot(wassdfbL2[\"date\"], wassdfbL2[\"wass1\"], color=color1, linestyle=\"--\", label=\"Dimension 1\")\n",
    "ax2.tick_params(axis='y', labelcolor=color1)\n",
    "\n",
    "# Title and formatting\n",
    "fig.suptitle(\"Wasserstein Distances Over Time\")\n",
    "fig.tight_layout()\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Add legends\n",
    "lines_1, labels_1 = ax1.get_legend_handles_labels()\n",
    "lines_2, labels_2 = ax2.get_legend_handles_labels()\n",
    "ax1.legend(lines_1 + lines_2, labels_1 + labels_2, loc=\"upper right\")\n",
    "\n",
    "plt.savefig(\"/Users/alexander/Documents/GitHub/TDA-and-GoogleTrends/figs/A_Wass.jpeg\", format=\"jpeg\", dpi=300)\n",
    "\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5428fa-8bc2-449e-9e3d-c6b6d0b3ed15",
   "metadata": {},
   "source": [
    "## B: Keyword and four lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b2a99282-a170-4125-9c59-82ffd33584dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stored diagrams\n",
    "diagd1 = pd.DataFrame(Bdiag_dim_1L2,columns=['Obs','b','d'])\n",
    "diagd0 = pd.DataFrame(Bdiag_dim_0L2,columns=['Obs','b','d'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b51a5079-560e-4d9c-a74c-6a92b7111147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collecting\n",
    "diagd150 = diagd1[(diagd1['Obs'] == 52)]\n",
    "diagd150 = diagd150[['b','d']]\n",
    "diagd151 = diagd1[(diagd1['Obs'] == 53)]\n",
    "diagd151 = diagd151[['b','d']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "093039c8-9199-4bd6-8bb5-d9813876f5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating distances\n",
    "diagd150a = diagd150.to_numpy()\n",
    "diagd151a = diagd151.to_numpy()\n",
    "\n",
    "dist = gd.hera.wasserstein_distance(diagd150a,diagd151a, order=1., internal_p=2.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "47dfc8c2-9005-4f31-ba2c-f0aa8190c9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blank arrays\n",
    "wass0 = []\n",
    "wass1 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a61b90d8-48e1-4aa1-88b8-6595aa938d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape\n",
    "r,c = embed5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a6dea8a4-4305-454b-a76e-64e460a674ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collection of Wasserstein distances\n",
    "r3 = r-1\n",
    "\n",
    "for i in range(ww,r3):\n",
    " a005 = i+1\n",
    " diagd150 = diagd1[(diagd1['Obs'] == i)]\n",
    " diagd150 = diagd150[['b','d']]\n",
    " diagd151 = diagd1[(diagd1['Obs'] == a005)]\n",
    " diagd151 = diagd151[['b','d']]\n",
    " diagd150a = diagd150.to_numpy()\n",
    " diagd151a = diagd151.to_numpy()\n",
    " dist = gudhi.hera.wasserstein_distance(diagd150a,diagd151a, order=1., internal_p=2.)\n",
    " wass1.append([a005,dist])\n",
    " diagd150 = diagd0[(diagd0['Obs'] == i)]\n",
    " diagd150 = diagd150[['b','d']]\n",
    " diagd151 = diagd0[(diagd0['Obs'] == a005)]\n",
    " diagd151 = diagd151[['b','d']]\n",
    " diagd150a = diagd150.to_numpy()\n",
    " diagd151a = diagd151.to_numpy()\n",
    " dist = gudhi.hera.wasserstein_distance(diagd150a,diagd151a, order=1., internal_p=2.)\n",
    " wass0.append([a005,dist])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4baa0144-0c6d-449f-ae64-7549b5db5a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Into dataframes\n",
    "wass0dfL2 = pd.DataFrame(wass0)\n",
    "wass0dfL2.columns = ['Obs','wass0']\n",
    "\n",
    "wass1dfL2 = pd.DataFrame(wass1)\n",
    "wass1dfL2.columns = ['Obs','wass1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d233bedc-88c5-43ce-a3e0-caf0086e4b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge\n",
    "wass0dfbL2 = wass0dfL2.merge(dffbL2,on='Obs')\n",
    "wassdfbL2 = wass0dfbL2.merge(wass1dfL2,on='Obs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "24e497e1-84a4-466d-9bfc-66867dfdb135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure date is datetime\n",
    "wassdfbL2[\"date\"] = pd.to_datetime(wassdfbL2[\"date\"])\n",
    "\n",
    "# Set up the figure and primary axis\n",
    "fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Plot Dimension 0 (left y-axis)\n",
    "color0 = \"tab:blue\"\n",
    "ax1.set_xlabel(\"Date\")\n",
    "ax1.set_ylabel(\"Wasserstein Distance (Dim 0)\", color=color0)\n",
    "ax1.plot(wassdfbL2[\"date\"], wassdfbL2[\"wass0\"], color=color0, label=\"Dimension 0\")\n",
    "ax1.tick_params(axis='y', labelcolor=color0)\n",
    "\n",
    "# Add secondary y-axis for Dimension 1\n",
    "ax2 = ax1.twinx()\n",
    "color1 = \"tab:orange\"\n",
    "ax2.set_ylabel(\"Wasserstein Distance (Dim 1)\", color=color1)\n",
    "ax2.plot(wassdfbL2[\"date\"], wassdfbL2[\"wass1\"], color=color1, linestyle=\"--\", label=\"Dimension 1\")\n",
    "ax2.tick_params(axis='y', labelcolor=color1)\n",
    "\n",
    "# Title and formatting\n",
    "fig.suptitle(\"Wasserstein Distances Over Time\")\n",
    "fig.tight_layout()\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Add legends\n",
    "lines_1, labels_1 = ax1.get_legend_handles_labels()\n",
    "lines_2, labels_2 = ax2.get_legend_handles_labels()\n",
    "ax1.legend(lines_1 + lines_2, labels_1 + labels_2, loc=\"upper right\")\n",
    "\n",
    "plt.savefig(\"/Users/alexander/Documents/GitHub/TDA-and-GoogleTrends/figs/B_Wass.jpeg\", format=\"jpeg\", dpi=300)\n",
    "\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19779036-d3e4-4ddb-b10a-b5cd274be98c",
   "metadata": {},
   "source": [
    "## C: Keyword and 1 related term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9e82af5c-2d66-41d4-bc9d-a141eff4ceaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stored diagrams\n",
    "diagd1 = pd.DataFrame(Cdiag_dim_1W2,columns=['Obs','b','d'])\n",
    "diagd0 = pd.DataFrame(Cdiag_dim_0W2,columns=['Obs','b','d'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "54a51877-481b-4b1a-ae69-ad3fd87bfabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collecting\n",
    "diagd150 = diagd1[(diagd1['Obs'] == 52)]\n",
    "diagd150 = diagd150[['b','d']]\n",
    "diagd151 = diagd1[(diagd1['Obs'] == 53)]\n",
    "diagd151 = diagd151[['b','d']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b0ca60c4-3b77-4ddb-9289-2526c252d0ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating distances\n",
    "diagd150a = diagd150.to_numpy()\n",
    "diagd151a = diagd151.to_numpy()\n",
    "\n",
    "dist = gd.hera.wasserstein_distance(diagd150a,diagd151a, order=1., internal_p=2.)\n",
    "\n",
    "dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "775a68fd-8297-4ab9-894e-b33479da6d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blank arrays\n",
    "wass0 = []\n",
    "wass1 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "435a0963-8f20-401f-a04b-9846b44c673b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape\n",
    "r,c = newdf2W2.shape\n",
    "\n",
    "# Wasserstein distances\n",
    "r3 = r-1\n",
    "\n",
    "for i in range(ww,r3):\n",
    " a005 = i+1\n",
    " diagd150 = diagd1[(diagd1['Obs'] == i)]\n",
    " diagd150 = diagd150[['b','d']]\n",
    " diagd151 = diagd1[(diagd1['Obs'] == a005)]\n",
    " diagd151 = diagd151[['b','d']]\n",
    " diagd150a = diagd150.to_numpy()\n",
    " diagd151a = diagd151.to_numpy()\n",
    " dist = gudhi.hera.wasserstein_distance(diagd150a,diagd151a, order=1., internal_p=2.)\n",
    " wass1.append([a005,dist])\n",
    " diagd150 = diagd0[(diagd0['Obs'] == i)]\n",
    " diagd150 = diagd150[['b','d']]\n",
    " diagd151 = diagd0[(diagd0['Obs'] == a005)]\n",
    " diagd151 = diagd151[['b','d']]\n",
    " diagd150a = diagd150.to_numpy()\n",
    " diagd151a = diagd151.to_numpy()\n",
    " dist = gudhi.hera.wasserstein_distance(diagd150a,diagd151a, order=1., internal_p=2.)\n",
    " wass0.append([a005,dist])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "974c4fe1-0aa2-415b-a66a-853e08e2af30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Into dataframes\n",
    "wass0dfW2 = pd.DataFrame(wass0)\n",
    "wass0dfW2.columns = ['Obs','wass0']\n",
    "\n",
    "wass1dfW2 = pd.DataFrame(wass1)\n",
    "wass1dfW2.columns = ['Obs','wass1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9d43bb77-1262-4d7b-a686-62f8bbd7b3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "wass0dfaW2 = wass0dfW2.iloc[1:,]\n",
    "wass1dfaW2 = wass1dfW2.iloc[1:,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7ecf9d08-40df-48f4-bcac-3955328c95fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge\n",
    "wass0dfbW2 = wass0dfaW2.merge(newdf2bW2,on='Obs')\n",
    "wassdfbW2 = wass0dfbW2.merge(wass1dfaW2,on='Obs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "bd2d06b6-e1bd-4fa4-bbd8-28fe1b6ff652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure date is datetime\n",
    "wassdfbW2[\"date\"] = pd.to_datetime(wassdfbW2[\"date\"])\n",
    "\n",
    "# Set up the figure and primary axis\n",
    "fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Plot Dimension 0 (left y-axis)\n",
    "color0 = \"tab:blue\"\n",
    "ax1.set_xlabel(\"Date\")\n",
    "ax1.set_ylabel(\"Wasserstein Distance (Dim 0)\", color=color0)\n",
    "ax1.plot(wassdfbW2[\"date\"], wassdfbW2[\"wass0\"], color=color0, label=\"Dimension 0\")\n",
    "ax1.tick_params(axis='y', labelcolor=color0)\n",
    "\n",
    "# Add secondary y-axis for Dimension 1\n",
    "ax2 = ax1.twinx()\n",
    "color1 = \"tab:orange\"\n",
    "ax2.set_ylabel(\"Wasserstein Distance (Dim 1)\", color=color1)\n",
    "ax2.plot(wassdfbW2[\"date\"], wassdfbW2[\"wass1\"], color=color1, linestyle=\"--\", label=\"Dimension 1\")\n",
    "ax2.tick_params(axis='y', labelcolor=color1)\n",
    "\n",
    "# Title and formatting\n",
    "fig.suptitle(\"Wasserstein Distances Over Time\")\n",
    "fig.tight_layout()\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Add legends\n",
    "lines_1, labels_1 = ax1.get_legend_handles_labels()\n",
    "lines_2, labels_2 = ax2.get_legend_handles_labels()\n",
    "ax1.legend(lines_1 + lines_2, labels_1 + labels_2, loc=\"upper right\")\n",
    "\n",
    "plt.savefig(\"/Users/alexander/Documents/GitHub/TDA-and-GoogleTrends/figs/C_wass.jpeg\", format=\"jpeg\", dpi=300)\n",
    "\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c0c49d-0784-4f02-8cb1-bcbcdd089a7d",
   "metadata": {},
   "source": [
    "## D: Full word cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "66751210-2f47-4ba7-8270-1f53823d3a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stored diagrams\n",
    "diagd1 = pd.DataFrame(Ddiag_dim_1W2,columns=['Obs','b','d'])\n",
    "diagd0 = pd.DataFrame(Ddiag_dim_0W2,columns=['Obs','b','d'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5871334a-9f80-4c9d-918e-ccae79ff4f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collecting diagrams\n",
    "diagd150 = diagd1[(diagd1['Obs'] == 52)]\n",
    "diagd150 = diagd150[['b','d']]\n",
    "diagd151 = diagd1[(diagd1['Obs'] == 53)]\n",
    "diagd151 = diagd151[['b','d']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "745ac60a-810a-4933-95a6-16d300dd449d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating distances\n",
    "diagd150a = diagd150.to_numpy()\n",
    "diagd151a = diagd151.to_numpy()\n",
    "\n",
    "dist = gd.hera.wasserstein_distance(diagd150a,diagd151a, order=1., internal_p=2.)\n",
    "\n",
    "dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b23642f9-6fab-4133-8fed-047d10209c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blank arrays\n",
    "wass0 = []\n",
    "wass1 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "dcc4f67d-023c-4d5f-a4a0-23d82e581e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape\n",
    "r,c = newdf2W2.shape\n",
    "\n",
    "r3 = r-1\n",
    "\n",
    "# Wasserstein distances\n",
    "for i in range(ww,r3):\n",
    " a005 = i+1\n",
    " diagd150 = diagd1[(diagd1['Obs'] == i)]\n",
    " diagd150 = diagd150[['b','d']]\n",
    " diagd151 = diagd1[(diagd1['Obs'] == a005)]\n",
    " diagd151 = diagd151[['b','d']]\n",
    " diagd150a = diagd150.to_numpy()\n",
    " diagd151a = diagd151.to_numpy()\n",
    " dist = gudhi.hera.wasserstein_distance(diagd150a,diagd151a, order=1., internal_p=2.)\n",
    " wass1.append([a005,dist])\n",
    " diagd150 = diagd0[(diagd0['Obs'] == i)]\n",
    " diagd150 = diagd150[['b','d']]\n",
    " diagd151 = diagd0[(diagd0['Obs'] == a005)]\n",
    " diagd151 = diagd151[['b','d']]\n",
    " diagd150a = diagd150.to_numpy()\n",
    " diagd151a = diagd151.to_numpy()\n",
    " dist = gudhi.hera.wasserstein_distance(diagd150a,diagd151a, order=1., internal_p=2.)\n",
    " wass0.append([a005,dist])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4c05eb57-5d87-45ce-af08-414521c8e9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Into dataframes\n",
    "wass0dfW2 = pd.DataFrame(wass0)\n",
    "wass0dfW2.columns = ['Obs','wass0']\n",
    "\n",
    "wass1dfW2 = pd.DataFrame(wass1)\n",
    "wass1dfW2.columns = ['Obs','wass1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c8108f03-977a-4235-b774-3110946e86f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "wass0dfaW2 = wass0dfW2.iloc[1:,]\n",
    "wass1dfaW2 = wass1dfW2.iloc[1:,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0c46349b-71f5-4b63-8653-a2e1d3e0ce38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge\n",
    "wass0dfbW2 = wass0dfaW2.merge(newdf2bW2,on='Obs')\n",
    "wassdfbW2 = wass0dfbW2.merge(wass1dfaW2,on='Obs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6c3076d2-cf3f-49de-8400-c576278d11ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure date is datetime\n",
    "wassdfbW2[\"date\"] = pd.to_datetime(wassdfbW2[\"date\"])\n",
    "\n",
    "# Set up the figure and primary axis\n",
    "fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Plot Dimension 0 (left y-axis)\n",
    "color0 = \"tab:blue\"\n",
    "ax1.set_xlabel(\"Date\")\n",
    "ax1.set_ylabel(\"Wasserstein Distance (Dim 0)\", color=color0)\n",
    "ax1.plot(wassdfbW2[\"date\"], wassdfbW2[\"wass0\"], color=color0, label=\"Dimension 0\")\n",
    "ax1.tick_params(axis='y', labelcolor=color0)\n",
    "\n",
    "# Add secondary y-axis for Dimension 1\n",
    "ax2 = ax1.twinx()\n",
    "color1 = \"tab:orange\"\n",
    "ax2.set_ylabel(\"Wasserstein Distance (Dim 1)\", color=color1)\n",
    "ax2.plot(wassdfbW2[\"date\"], wassdfbW2[\"wass1\"], color=color1, linestyle=\"--\", label=\"Dimension 1\")\n",
    "ax2.tick_params(axis='y', labelcolor=color1)\n",
    "\n",
    "# Title and formatting\n",
    "fig.suptitle(\"Wasserstein Distances Over Time\")\n",
    "fig.tight_layout()\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Add legends\n",
    "lines_1, labels_1 = ax1.get_legend_handles_labels()\n",
    "lines_2, labels_2 = ax2.get_legend_handles_labels()\n",
    "ax1.legend(lines_1 + lines_2, labels_1 + labels_2, loc=\"upper right\")\n",
    "\n",
    "plt.savefig(\"/Users/alexander/Documents/GitHub/TDA-and-GoogleTrends/figs/D_wass.jpeg\", format=\"jpeg\", dpi=300)\n",
    "\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
